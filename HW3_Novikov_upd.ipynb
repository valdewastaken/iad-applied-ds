{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW3_Novikov.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExuV3ktSQYrH"
      },
      "source": [
        "# Введение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef6180WvQbD-"
      },
      "source": [
        "В этом задании Вы продолжите работать с данными из семинара [Articles Sharing and Reading from CI&T Deskdrop](https://www.kaggle.com/gspmoreira/articles-sharing-reading-from-cit-deskdrop)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5mH3ZolSlcm"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSV_mxD9TciM"
      },
      "source": [
        "## Загрузка и предобработка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRQVuRvER0hd"
      },
      "source": [
        "Загрузим данные и проведем предобраотку данных как на семинаре."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E837g9kQTbb"
      },
      "source": [
        "!wget -q -N https://www.dropbox.com/s/z8syrl5trawxs0n/articles.zip?dl=0 -O articles.zip\n",
        "!unzip -o -q articles.zip"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "hdM1xSchR9jt",
        "outputId": "7b71a780-1c0f-4a30-ad9b-5eb1292d90c4"
      },
      "source": [
        "articles_df = pd.read_csv('articles/shared_articles.csv')\n",
        "articles_df = articles_df[articles_df['eventType'] == 'CONTENT SHARED']\n",
        "articles_df.head(2)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>eventType</th>\n",
              "      <th>contentId</th>\n",
              "      <th>authorPersonId</th>\n",
              "      <th>authorSessionId</th>\n",
              "      <th>authorUserAgent</th>\n",
              "      <th>authorRegion</th>\n",
              "      <th>authorCountry</th>\n",
              "      <th>contentType</th>\n",
              "      <th>url</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>lang</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1459193988</td>\n",
              "      <td>CONTENT SHARED</td>\n",
              "      <td>-4110354420726924665</td>\n",
              "      <td>4340306774493623681</td>\n",
              "      <td>8940341205206233829</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>HTML</td>\n",
              "      <td>http://www.nytimes.com/2016/03/28/business/dea...</td>\n",
              "      <td>Ethereum, a Virtual Currency, Enables Transact...</td>\n",
              "      <td>All of this work is still very early. The firs...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1459194146</td>\n",
              "      <td>CONTENT SHARED</td>\n",
              "      <td>-7292285110016212249</td>\n",
              "      <td>4340306774493623681</td>\n",
              "      <td>8940341205206233829</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>HTML</td>\n",
              "      <td>http://cointelegraph.com/news/bitcoin-future-w...</td>\n",
              "      <td>Bitcoin Future: When GBPcoin of Branson Wins O...</td>\n",
              "      <td>The alarm clock wakes me at 8:00 with stream o...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    timestamp  ... lang\n",
              "1  1459193988  ...   en\n",
              "2  1459194146  ...   en\n",
              "\n",
              "[2 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "KK9wMAkvSjbk",
        "outputId": "1af2cbf4-eb3d-4356-ee40-aacb90d78787"
      },
      "source": [
        "interactions_df = pd.read_csv('articles/users_interactions.csv')\n",
        "interactions_df.head(2)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>eventType</th>\n",
              "      <th>contentId</th>\n",
              "      <th>personId</th>\n",
              "      <th>sessionId</th>\n",
              "      <th>userAgent</th>\n",
              "      <th>userRegion</th>\n",
              "      <th>userCountry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1465413032</td>\n",
              "      <td>VIEW</td>\n",
              "      <td>-3499919498720038879</td>\n",
              "      <td>-8845298781299428018</td>\n",
              "      <td>1264196770339959068</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1465412560</td>\n",
              "      <td>VIEW</td>\n",
              "      <td>8890720798209849691</td>\n",
              "      <td>-1032019229384696495</td>\n",
              "      <td>3621737643587579081</td>\n",
              "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2...</td>\n",
              "      <td>NY</td>\n",
              "      <td>US</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    timestamp eventType  ...  userRegion  userCountry\n",
              "0  1465413032      VIEW  ...         NaN          NaN\n",
              "1  1465412560      VIEW  ...          NY           US\n",
              "\n",
              "[2 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nQScdSTTzNG"
      },
      "source": [
        "interactions_df.personId = interactions_df.personId.astype(str)\n",
        "interactions_df.contentId = interactions_df.contentId.astype(str)\n",
        "articles_df.contentId = articles_df.contentId.astype(str)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eu6R9rDQT2P4"
      },
      "source": [
        "# зададим словарь определяющий силу взаимодействия\n",
        "event_type_strength = {\n",
        "   'VIEW': 1.0,\n",
        "   'LIKE': 2.0, \n",
        "   'BOOKMARK': 2.5, \n",
        "   'FOLLOW': 3.0,\n",
        "   'COMMENT CREATED': 4.0,  \n",
        "}\n",
        "\n",
        "interactions_df['eventStrength'] = interactions_df.eventType.apply(lambda x: event_type_strength[x])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATO5PRRwUkQ0"
      },
      "source": [
        "Оставляем только тех пользователей, которые произамодействовали более чем с пятью статьями."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-0HoboYUBm5",
        "outputId": "b1bd9f40-bf16-43f4-c8a6-e9ba146894a0"
      },
      "source": [
        "users_interactions_count_df = (\n",
        "    interactions_df\n",
        "    .groupby(['personId', 'contentId'])\n",
        "    .first()\n",
        "    .reset_index()\n",
        "    .groupby('personId').size())\n",
        "print('# users:', len(users_interactions_count_df))\n",
        "\n",
        "users_with_enough_interactions_df = \\\n",
        "    users_interactions_count_df[users_interactions_count_df >= 5].reset_index()[['personId']]\n",
        "print('# users with at least 5 interactions:',len(users_with_enough_interactions_df))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# users: 1895\n",
            "# users with at least 5 interactions: 1140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQagI3DHUuX5"
      },
      "source": [
        "Оставляем только те взаимодействия, которые относятся к отфильтрованным пользователям."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34rrdGdpUFgk"
      },
      "source": [
        "interactions_from_selected_users_df = interactions_df.loc[np.in1d(interactions_df.personId,\n",
        "            users_with_enough_interactions_df)]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hd3VS_BgU9HN",
        "outputId": "0a127613-bf6a-4da5-df13-7fbc4ba12cbe"
      },
      "source": [
        "print('# interactions before:', interactions_df.shape)\n",
        "print('# interactions after:', interactions_from_selected_users_df.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# interactions before: (72312, 9)\n",
            "# interactions after: (69868, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYpRiFkQVR6B"
      },
      "source": [
        "Объединяем все взаимодействия пользователя по каждой статье и сглаживаем полученный результат, взяв от него логарифм."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mtPtAehKVEUu",
        "outputId": "1308096e-e4b0-4e3c-b92c-3cfed412abbc"
      },
      "source": [
        "def smooth_user_preference(x):\n",
        "    return math.log(1+x, 2)\n",
        "    \n",
        "interactions_full_df = (\n",
        "    interactions_from_selected_users_df\n",
        "    .groupby(['personId', 'contentId']).eventStrength.sum()\n",
        "    .apply(smooth_user_preference)\n",
        "    .reset_index().set_index(['personId', 'contentId'])\n",
        ")\n",
        "interactions_full_df['last_timestamp'] = (\n",
        "    interactions_from_selected_users_df\n",
        "    .groupby(['personId', 'contentId'])['timestamp'].last()\n",
        ")\n",
        "        \n",
        "interactions_full_df = interactions_full_df.reset_index()\n",
        "interactions_full_df.head(5)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>personId</th>\n",
              "      <th>contentId</th>\n",
              "      <th>eventStrength</th>\n",
              "      <th>last_timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1007001694607905623</td>\n",
              "      <td>-5065077552540450930</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1470395911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1007001694607905623</td>\n",
              "      <td>-6623581327558800021</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1487240080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1007001694607905623</td>\n",
              "      <td>-793729620925729327</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1472834892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1007001694607905623</td>\n",
              "      <td>1469580151036142903</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1487240062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1007001694607905623</td>\n",
              "      <td>7270966256391553686</td>\n",
              "      <td>1.584963</td>\n",
              "      <td>1485994324</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               personId             contentId  eventStrength  last_timestamp\n",
              "0  -1007001694607905623  -5065077552540450930       1.000000      1470395911\n",
              "1  -1007001694607905623  -6623581327558800021       1.000000      1487240080\n",
              "2  -1007001694607905623   -793729620925729327       1.000000      1472834892\n",
              "3  -1007001694607905623   1469580151036142903       1.000000      1487240062\n",
              "4  -1007001694607905623   7270966256391553686       1.584963      1485994324"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODJYMtnNWM5w"
      },
      "source": [
        "Разобьём выборку на обучение и контроль по времени."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "3F2CfAwoVrfo",
        "outputId": "17a31a19-60bd-4ab7-cbc5-5773579ef1fc"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "split_ts = 1475519530\n",
        "interactions_train_df = interactions_full_df.loc[interactions_full_df.last_timestamp < split_ts].copy()\n",
        "interactions_test_df = interactions_full_df.loc[interactions_full_df.last_timestamp >= split_ts].copy()\n",
        "\n",
        "print('# interactions on Train set: %d' % len(interactions_train_df))\n",
        "print('# interactions on Test set: %d' % len(interactions_test_df))\n",
        "\n",
        "interactions_train_df"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# interactions on Train set: 29329\n",
            "# interactions on Test set: 9777\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>personId</th>\n",
              "      <th>contentId</th>\n",
              "      <th>eventStrength</th>\n",
              "      <th>last_timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1007001694607905623</td>\n",
              "      <td>-5065077552540450930</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1470395911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1007001694607905623</td>\n",
              "      <td>-793729620925729327</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1472834892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-1032019229384696495</td>\n",
              "      <td>-1006791494035379303</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1469129122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-1032019229384696495</td>\n",
              "      <td>-1039912738963181810</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1459376415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-1032019229384696495</td>\n",
              "      <td>-1081723567492738167</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1464054093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39099</th>\n",
              "      <td>997469202936578234</td>\n",
              "      <td>9112765177685685246</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1472479493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39100</th>\n",
              "      <td>998688566268269815</td>\n",
              "      <td>-1255189867397298842</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1474567164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39101</th>\n",
              "      <td>998688566268269815</td>\n",
              "      <td>-401664538366009049</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1474567449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39103</th>\n",
              "      <td>998688566268269815</td>\n",
              "      <td>6881796783400625893</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1474567675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39105</th>\n",
              "      <td>998688566268269815</td>\n",
              "      <td>739747367187387064</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1474567514</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29329 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   personId  ... last_timestamp\n",
              "0      -1007001694607905623  ...     1470395911\n",
              "2      -1007001694607905623  ...     1472834892\n",
              "6      -1032019229384696495  ...     1469129122\n",
              "7      -1032019229384696495  ...     1459376415\n",
              "8      -1032019229384696495  ...     1464054093\n",
              "...                     ...  ...            ...\n",
              "39099    997469202936578234  ...     1472479493\n",
              "39100    998688566268269815  ...     1474567164\n",
              "39101    998688566268269815  ...     1474567449\n",
              "39103    998688566268269815  ...     1474567675\n",
              "39105    998688566268269815  ...     1474567514\n",
              "\n",
              "[29329 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5G3FTYOXLVg"
      },
      "source": [
        "Для удобства подсчёта качества запишем данные в формате, где строка соответствует пользователю, а столбцы будут истинными метками и предсказаниями в виде списков."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "RT-_toqfXOa2",
        "outputId": "4c485182-b3c6-4dc9-b73a-9d5dfc32bc22"
      },
      "source": [
        "interactions = (\n",
        "    interactions_train_df\n",
        "    .groupby('personId')['contentId'].agg(lambda x: list(x))\n",
        "    .reset_index()\n",
        "    .rename(columns={'contentId': 'true_train'})\n",
        "    .set_index('personId')\n",
        ")\n",
        "\n",
        "interactions['true_test'] = (\n",
        "    interactions_test_df\n",
        "    .groupby('personId')['contentId'].agg(lambda x: list(x))\n",
        ")\n",
        "\n",
        "# заполнение пропусков пустыми списками\n",
        "interactions.loc[pd.isnull(interactions.true_test), 'true_test'] = [\n",
        "    list() for x in range(len(interactions.loc[pd.isnull(interactions.true_test), 'true_test']))]\n",
        "\n",
        "interactions.head(1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>true_train</th>\n",
              "      <th>true_test</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>personId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>-1007001694607905623</th>\n",
              "      <td>[-5065077552540450930, -793729620925729327]</td>\n",
              "      <td>[-6623581327558800021, 1469580151036142903, 72...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                       true_train                                          true_test\n",
              "personId                                                                                                            \n",
              "-1007001694607905623  [-5065077552540450930, -793729620925729327]  [-6623581327558800021, 1469580151036142903, 72..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UWDyWKsamSa"
      },
      "source": [
        "## Библиотека LightFM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-iXjvdZa25Z"
      },
      "source": [
        "Для рекомендации Вы будете пользоваться библиотекой [LightFM](https://making.lyst.com/lightfm/docs/home.html), в которой реализованы популярные алгоритмы. Для оценивания качества рекомендации, как и на семинаре, будем пользоваться метрикой *precision@10*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qtyn38PZXPLf",
        "outputId": "1ffb76ab-4ba9-4568-c41e-14f248b7bba1"
      },
      "source": [
        "!pip install lightfm\n",
        "from lightfm import LightFM\n",
        "from lightfm.evaluation import precision_at_k"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightfm in /usr/local/lib/python3.7/dist-packages (1.16)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightfm) (0.22.2.post1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from lightfm) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightfm) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from lightfm) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightfm) (1.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPYAKL-uD-f6"
      },
      "source": [
        "from lightfm.data import Dataset"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CjyGqulcZTf"
      },
      "source": [
        "## Задание 1. (2 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Sof6V5Dd4h9"
      },
      "source": [
        "Модели в LightFM работают с разреженными матрицами. Создайте разреженные матрицы `data_train` и `data_test` (размером количество пользователей на количество статей), такие что на пересечении строки пользователя и столбца статьи стоит сила их взаимодействия, если взаимодействие было, и стоит ноль, если взаимодействия не было."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8Iw9u2UVzkT"
      },
      "source": [
        "Проблема (вроде как) в том, что по умолчанию если взаимодействия не было lightfm Dataset ставит 1.0, поэтому надо в функции ```_unpack_datum``` поменять параметр ```weight = 1.0``` на ```weight = 0.0``` при условии ```len(datum) = 2```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOzjupsNVbPw"
      },
      "source": [
        "import array\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import scipy.sparse as sp\n",
        "\n",
        "import sklearn.preprocessing\n",
        "\n",
        "\n",
        "class _IncrementalCOOMatrix(object):\n",
        "    def __init__(self, shape, dtype):\n",
        "\n",
        "        if dtype is np.int32:\n",
        "            type_flag = \"i\"\n",
        "        elif dtype is np.int64:\n",
        "            type_flag = \"l\"\n",
        "        elif dtype is np.float32:\n",
        "            type_flag = \"f\"\n",
        "        elif dtype is np.float64:\n",
        "            type_flag = \"d\"\n",
        "        else:\n",
        "            raise Exception(\"Dtype not supported.\")\n",
        "\n",
        "        self.shape = shape\n",
        "        self.dtype = dtype\n",
        "\n",
        "        self.rows = array.array(\"i\")\n",
        "        self.cols = array.array(\"i\")\n",
        "        self.data = array.array(type_flag)\n",
        "\n",
        "    def append(self, i, j, v):\n",
        "\n",
        "        m, n = self.shape\n",
        "\n",
        "        if i >= m or j >= n:\n",
        "            raise Exception(\"Index out of bounds\")\n",
        "\n",
        "        self.rows.append(i)\n",
        "        self.cols.append(j)\n",
        "        self.data.append(v)\n",
        "\n",
        "    def tocoo(self):\n",
        "\n",
        "        rows = np.frombuffer(self.rows, dtype=np.int32)\n",
        "        cols = np.frombuffer(self.cols, dtype=np.int32)\n",
        "        data = np.frombuffer(self.data, dtype=self.dtype)\n",
        "\n",
        "        return sp.coo_matrix((data, (rows, cols)), shape=self.shape)\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "class _FeatureBuilder(object):\n",
        "    def __init__(\n",
        "        self, id_mapping, feature_mapping, identity_features, normalize, entity_type\n",
        "    ):\n",
        "\n",
        "        self._id_mapping = id_mapping\n",
        "        self._feature_mapping = feature_mapping\n",
        "        self._identity_features = identity_features\n",
        "        self._normalize = normalize\n",
        "        self._entity_type = entity_type\n",
        "\n",
        "    def features_shape(self):\n",
        "\n",
        "        return len(self._id_mapping), len(self._feature_mapping)\n",
        "\n",
        "    def _iter_features(self, features):\n",
        "\n",
        "        if isinstance(features, dict):\n",
        "            for entry in features.items():\n",
        "                yield entry\n",
        "\n",
        "        else:\n",
        "            for feature_name in features:\n",
        "                yield (feature_name, 1.0)\n",
        "\n",
        "    def _process_features(self, datum):\n",
        "\n",
        "        if len(datum) != 2:\n",
        "            raise ValueError(\n",
        "                \"Expected tuples of ({}_id, features), \"\n",
        "                \"got {}.\".format(self._entity_type, datum)\n",
        "            )\n",
        "\n",
        "        entity_id, features = datum\n",
        "\n",
        "        if entity_id not in self._id_mapping:\n",
        "            raise ValueError(\n",
        "                \"{entity_type} id {entity_id} not in {entity_type} id mappings.\".format(\n",
        "                    entity_type=self._entity_type, entity_id=entity_id\n",
        "                )\n",
        "            )\n",
        "\n",
        "        idx = self._id_mapping[entity_id]\n",
        "\n",
        "        for (feature, weight) in self._iter_features(features):\n",
        "            if feature not in self._feature_mapping:\n",
        "                raise ValueError(\n",
        "                    \"Feature {} not in feature mapping. \"\n",
        "                    \"Call fit first.\".format(feature)\n",
        "                )\n",
        "\n",
        "            feature_idx = self._feature_mapping[feature]\n",
        "\n",
        "            yield (idx, feature_idx, weight)\n",
        "\n",
        "    def build(self, data):\n",
        "\n",
        "        features = _IncrementalCOOMatrix(self.features_shape(), np.float32)\n",
        "\n",
        "        if self._identity_features:\n",
        "            for (_id, idx) in self._id_mapping.items():\n",
        "                features.append(idx, self._feature_mapping[_id], 1.0)\n",
        "\n",
        "        for datum in data:\n",
        "            for (entity_idx, feature_idx, weight) in self._process_features(datum):\n",
        "                features.append(entity_idx, feature_idx, weight)\n",
        "\n",
        "        features = features.tocoo().tocsr()\n",
        "\n",
        "        if self._normalize:\n",
        "            if np.any(features.getnnz(1) == 0):\n",
        "                raise ValueError(\n",
        "                    \"Cannot normalize feature matrix: some rows have zero norm. \"\n",
        "                    \"Ensure that features were provided for all entries.\"\n",
        "                )\n",
        "\n",
        "            sklearn.preprocessing.normalize(features, norm=\"l1\", copy=False)\n",
        "\n",
        "        return features\n",
        "\n",
        "\n",
        "class Dataset(object):\n",
        "    \"\"\"\n",
        "    Tool for building interaction and feature matrices, taking care of the\n",
        "    mapping between user/item ids and feature names and internal feature indices.\n",
        "    To create a dataset:\n",
        "    - Create an instance of the `Dataset` class.\n",
        "    - Call `fit` (or `fit_partial`), supplying user/item ids and feature names\n",
        "      that you want to use in your model. This will create internal mappings that\n",
        "      translate the ids and feature names to internal indices used by the LightFM\n",
        "      model.\n",
        "    - Call `build_interactions` with an iterable of (user id, item id) or (user id,\n",
        "      item id, weight) to build an interactions and weights matrix.\n",
        "    - Call `build_user/item_features` with iterables of (user/item id, [features])\n",
        "      or (user/item id, {feature: feature weight}) to build feature matrices.\n",
        "    - To add new user/item ids or features, call `fit_partial` again. You will need\n",
        "      to resize your LightFM model to be able to use the new features.\n",
        "    Parameters\n",
        "    ----------\n",
        "    user_identity_features: bool, optional\n",
        "        Create a unique feature for every user in addition to other features.\n",
        "        If true (default), a latent vector will be allocated for every user. This\n",
        "        is a reasonable default for most applications, but should be set to false\n",
        "        if there is very little data for every user. For more details see the Notes\n",
        "        in :doc:`LightFM<lightfm>`.\n",
        "    item_identity_features: bool, optional\n",
        "        Create a unique feature for every item in addition to other features.\n",
        "        If true (default), a latent vector will be allocated for every item. This\n",
        "        is a reasonable default for most applications, but should be set to false\n",
        "        if there is very little data for every item. For more details see the Notes\n",
        "        in :doc:`LightFM<lightfm>`.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, user_identity_features=True, item_identity_features=True):\n",
        "\n",
        "        self._user_identity_features = user_identity_features\n",
        "        self._item_identity_features = item_identity_features\n",
        "\n",
        "        self._user_id_mapping = {}\n",
        "        self._item_id_mapping = {}\n",
        "        self._user_feature_mapping = {}\n",
        "        self._item_feature_mapping = {}\n",
        "\n",
        "    def _check_fitted(self):\n",
        "\n",
        "        if not self._user_id_mapping or not self._item_id_mapping:\n",
        "            raise ValueError(\n",
        "                \"You must call fit first to build the item and user \" \"id mappings.\"\n",
        "            )\n",
        "\n",
        "    def fit(self, users, items, user_features=None, item_features=None):\n",
        "        \"\"\"\n",
        "        Fit the user/item id and feature name mappings.\n",
        "        Calling fit the second time will reset existing mappings.\n",
        "        Parameters\n",
        "        ----------\n",
        "        users: iterable of user ids\n",
        "        items: iterable of item ids\n",
        "        user_features: iterable of user features, optional\n",
        "        item_features: iterable of item features, optional\n",
        "        \"\"\"\n",
        "\n",
        "        self._user_id_mapping = {}\n",
        "        self._item_id_mapping = {}\n",
        "        self._user_feature_mapping = {}\n",
        "        self._item_feature_mapping = {}\n",
        "\n",
        "        return self.fit_partial(users, items, user_features, item_features)\n",
        "\n",
        "    def fit_partial(\n",
        "        self, users=None, items=None, user_features=None, item_features=None\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Fit the user/item id and feature name mappings.\n",
        "        Calling fit the second time will add new entries to existing mappings.\n",
        "        Parameters\n",
        "        ----------\n",
        "        users: iterable of user ids, optional\n",
        "        items: iterable of item ids, optional\n",
        "        user_features: iterable of user features, optional\n",
        "        item_features: iterable of item features, optional\n",
        "        \"\"\"\n",
        "\n",
        "        if users is not None:\n",
        "            for user_id in users:\n",
        "                self._user_id_mapping.setdefault(user_id, len(self._user_id_mapping))\n",
        "\n",
        "                if self._user_identity_features:\n",
        "                    self._user_feature_mapping.setdefault(\n",
        "                        user_id, len(self._user_feature_mapping)\n",
        "                    )\n",
        "\n",
        "        if items is not None:\n",
        "            for item_id in items:\n",
        "                self._item_id_mapping.setdefault(item_id, len(self._item_id_mapping))\n",
        "\n",
        "                if self._item_identity_features:\n",
        "                    self._item_feature_mapping.setdefault(\n",
        "                        item_id, len(self._item_feature_mapping)\n",
        "                    )\n",
        "\n",
        "        if user_features is not None:\n",
        "            for user_feature in user_features:\n",
        "                self._user_feature_mapping.setdefault(\n",
        "                    user_feature, len(self._user_feature_mapping)\n",
        "                )\n",
        "\n",
        "        if item_features is not None:\n",
        "            for item_feature in item_features:\n",
        "                self._item_feature_mapping.setdefault(\n",
        "                    item_feature, len(self._item_feature_mapping)\n",
        "                )\n",
        "\n",
        "    def _unpack_datum(self, datum):\n",
        "\n",
        "        if len(datum) == 3:\n",
        "            (user_id, item_id, weight) = datum\n",
        "        elif len(datum) == 2:\n",
        "            (user_id, item_id) = datum\n",
        "            weight = 0.0\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                \"Expecting tuples of (user_id, item_id, weight) \"\n",
        "                \"or (user_id, item_id). Got {}\".format(datum)\n",
        "            )\n",
        "\n",
        "        user_idx = self._user_id_mapping.get(user_id)\n",
        "        item_idx = self._item_id_mapping.get(item_id)\n",
        "\n",
        "        if user_idx is None:\n",
        "            raise ValueError(\n",
        "                \"User id {} not in user id mapping. Make sure \"\n",
        "                \"you call the fit method.\".format(user_id)\n",
        "            )\n",
        "\n",
        "        if item_idx is None:\n",
        "            raise ValueError(\n",
        "                \"Item id {} not in item id mapping. Make sure \"\n",
        "                \"you call the fit method.\".format(item_id)\n",
        "            )\n",
        "\n",
        "        return (user_idx, item_idx, weight)\n",
        "\n",
        "    def interactions_shape(self):\n",
        "        \"\"\"\n",
        "        Return a tuple of (num users, num items).\n",
        "        \"\"\"\n",
        "\n",
        "        return (len(self._user_id_mapping), len(self._item_id_mapping))\n",
        "\n",
        "    def build_interactions(self, data):\n",
        "        \"\"\"\n",
        "        Build an interaction matrix.\n",
        "        Two matrices will be returned: a (num_users, num_items)\n",
        "        COO matrix with interactions, and a (num_users, num_items)\n",
        "        matrix with the corresponding interaction weights.\n",
        "        Parameters\n",
        "        ----------\n",
        "        data: iterable of (user_id, item_id) or (user_id, item_id, weight)\n",
        "            An iterable of interactions. The user and item ids will be\n",
        "            translated to internal model indices using the mappings\n",
        "            constructed during the fit call. If weights are not provided\n",
        "            they will be assumed to be 1.0.\n",
        "        Returns\n",
        "        -------\n",
        "        (interactions, weights): COO matrix, COO matrix\n",
        "            Two COO matrices: the interactions matrix\n",
        "            and the corresponding weights matrix.\n",
        "        \"\"\"\n",
        "\n",
        "        interactions = _IncrementalCOOMatrix(self.interactions_shape(), np.int32)\n",
        "        weights = _IncrementalCOOMatrix(self.interactions_shape(), np.float32)\n",
        "\n",
        "        for datum in data:\n",
        "            user_idx, item_idx, weight = self._unpack_datum(datum)\n",
        "\n",
        "            interactions.append(user_idx, item_idx, 1)\n",
        "            weights.append(user_idx, item_idx, weight)\n",
        "\n",
        "        return (interactions.tocoo(), weights.tocoo())\n",
        "\n",
        "    def user_features_shape(self):\n",
        "        \"\"\"\n",
        "        Return the shape of the user features matrix.\n",
        "        Returns\n",
        "        -------\n",
        "        (num user ids, num user features): tuple of ints\n",
        "            The shape.\n",
        "        \"\"\"\n",
        "\n",
        "        return (len(self._user_id_mapping), len(self._user_feature_mapping))\n",
        "\n",
        "    def build_user_features(self, data, normalize=True):\n",
        "        \"\"\"\n",
        "        Build a user features matrix out of an iterable of the form\n",
        "        (user id, [list of feature names]) or (user id, {feature name: feature weight}).\n",
        "        Parameters\n",
        "        ----------\n",
        "        data: iterable of the form\n",
        "            (user id, [list of feature names]) or (user id,\n",
        "            {feature name: feature weight}).\n",
        "            User and feature ids will be translated to internal indices\n",
        "            constructed during the fit call.\n",
        "        normalize: bool, optional\n",
        "            If true, will ensure that feature weights sum to 1 in every row.\n",
        "        Returns\n",
        "        -------\n",
        "        feature matrix: CSR matrix (num users, num features)\n",
        "            Matrix of user features.\n",
        "        \"\"\"\n",
        "\n",
        "        builder = _FeatureBuilder(\n",
        "            self._user_id_mapping,\n",
        "            self._user_feature_mapping,\n",
        "            self._user_identity_features,\n",
        "            normalize,\n",
        "            \"user\",\n",
        "        )\n",
        "\n",
        "        return builder.build(data)\n",
        "\n",
        "    def item_features_shape(self):\n",
        "        \"\"\"\n",
        "        Return the shape of the item features matrix.\n",
        "        Returns\n",
        "        -------\n",
        "        (num item ids, num item features): tuple of ints\n",
        "            The shape.\n",
        "        \"\"\"\n",
        "\n",
        "        return (len(self._item_id_mapping), len(self._item_feature_mapping))\n",
        "\n",
        "    def build_item_features(self, data, normalize=True):\n",
        "        \"\"\"\n",
        "        Build a item features matrix out of an iterable of the form\n",
        "        (item id, [list of feature names]) or (item id, {feature name: feature weight}).\n",
        "        Parameters\n",
        "        ----------\n",
        "        data: iterable of the form\n",
        "            (item id, [list of feature names]) or (item id,\n",
        "            {feature name: feature weight}).\n",
        "            Item and feature ids will be translated to internal indices\n",
        "            constructed during the fit call.\n",
        "        normalize: bool, optional\n",
        "            If true, will ensure that feature weights sum to 1 in every row.\n",
        "        Returns\n",
        "        -------\n",
        "        feature matrix: CSR matrix (num items, num features)\n",
        "            Matrix of item features.\n",
        "        \"\"\"\n",
        "\n",
        "        builder = _FeatureBuilder(\n",
        "            self._item_id_mapping,\n",
        "            self._item_feature_mapping,\n",
        "            self._item_identity_features,\n",
        "            normalize,\n",
        "            \"item\",\n",
        "        )\n",
        "\n",
        "        return builder.build(data)\n",
        "\n",
        "    def model_dimensions(self):\n",
        "        \"\"\"\n",
        "        Returns a tuple that characterizes the number of user/item feature\n",
        "        embeddings in a LightFM model for this dataset.\n",
        "        \"\"\"\n",
        "\n",
        "        return (len(self._user_feature_mapping), len(self._item_feature_mapping))\n",
        "\n",
        "    def mapping(self):\n",
        "        \"\"\"\n",
        "        Return the constructed mappings.\n",
        "        Invert these to map internal indices to external ids.\n",
        "        Returns\n",
        "        -------\n",
        "        (user id map, user feature map, item id map, item feature map): tuple of dictionaries\n",
        "        \"\"\"\n",
        "\n",
        "        return (\n",
        "            self._user_id_mapping,\n",
        "            self._user_feature_mapping,\n",
        "            self._item_id_mapping,\n",
        "            self._item_feature_mapping,\n",
        "        )"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cLZ5ga4eIdg"
      },
      "source": [
        "# Ваш код здесь\n",
        "\n",
        "data = Dataset()\n",
        "\n",
        "data.fit(interactions_full_df.personId.unique(),\n",
        "         interactions_full_df.contentId.unique())\n",
        "\n",
        "interactions_train, weights_train = data.build_interactions([tuple(i) for i in interactions_train_df[['personId', 'contentId', 'eventStrength']].values])\n",
        "interactions_test, weights_test = data.build_interactions([tuple(i) for i in interactions_test_df[['personId', 'contentId', 'eventStrength']].values])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiNGVzTveRXE"
      },
      "source": [
        "## Задание 2. (1 балл)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPfVK3STeryM"
      },
      "source": [
        "Обучите модель LightFM с `loss='warp'` и посчитайте *precision@10* на тесте."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFQxeHw8eVLz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5bdb73b-40b4-4f7c-f3d6-310a4449b7d6"
      },
      "source": [
        "# Ваш код здесь\n",
        "model = LightFM(loss='warp')\n",
        "model.fit(weights_train, epochs=30, num_threads=2)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightfm.lightfm.LightFM at 0x7fd8c6b83210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cANFR-bMsmh",
        "outputId": "c63745bf-3679-49ba-b2dd-b4d10e15d13f"
      },
      "source": [
        "precision_at_k(model, weights_train, k=10).mean()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2409173"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVi-ubCo12mI",
        "outputId": "75e11253-4607-4640-cafa-8bed4a0ac034"
      },
      "source": [
        "precision_at_k(model, weights_test, k=10).mean()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0037678208"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZDsG1iAfdrl"
      },
      "source": [
        "## Задание 3. (3 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F93chvtbgA9N"
      },
      "source": [
        "При вызове метода `fit` LightFM позволяет передавать в `item_features` признаковое описание объектов. Воспользуемся этим. Будем получать признаковое описание из текста статьи в виде [TF-IDF](https://ru.wikipedia.org/wiki/TF-IDF) (можно воспользоваться `TfidfVectorizer` из scikit-learn). Создайте матрицу `feat` размером количесвто статей на размер признакового описание и обучите LightFM с `loss='warp'` и посчитайте precision@10 на тесте."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_S5R4ui4jFK"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUMtGLbrG9qO"
      },
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmJMFDiomQnR"
      },
      "source": [
        "articles_df = articles_df[articles_df.contentId.isin(interactions_full_df.contentId.unique())]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJ7qHwKNm-6U"
      },
      "source": [
        "articles = pd.merge(left=interactions_full_df,\n",
        "                     right=articles_df[['contentId', 'text']],\n",
        "                     left_on='contentId', right_on='contentId',\n",
        "                    how='outer')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xN8nfPXctnw4",
        "outputId": "2b957ba6-e663-4c70-8eae-1af81f95c4ea"
      },
      "source": [
        "split_ts = 1475519530\n",
        "interactions_train_df = articles.loc[articles.last_timestamp < split_ts].copy()\n",
        "interactions_test_df = articles.loc[articles.last_timestamp >= split_ts].copy()\n",
        "\n",
        "print('# interactions on Train set: %d' % len(interactions_train_df))\n",
        "print('# interactions on Test set: %d' % len(interactions_test_df))\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# interactions on Train set: 29329\n",
            "# interactions on Test set: 9777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5dhR2B14l02"
      },
      "source": [
        "articles_short = articles.drop_duplicates(subset=['contentId'])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuzY0P3PG9cX"
      },
      "source": [
        "tfidf = TfidfVectorizer(min_df=50, max_features=50000).fit(list(articles_short['text'].astype('U')))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7q0HzFOyogd"
      },
      "source": [
        "tfidfs = tfidf.transform(list(articles_short['text'].astype('U')))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dpw5Jt2Rey40"
      },
      "source": [
        "data = Dataset()\n",
        "\n",
        "data.fit(articles.personId.unique(),\n",
        "         articles.contentId.unique(),\n",
        "         item_features = pd.DataFrame(tfidfs)\n",
        "         )"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdlkAioLWI6R"
      },
      "source": [
        "\n",
        "interactions_train, weights_train = data.build_interactions([tuple(i) for i in interactions_train_df[['personId', 'contentId', 'eventStrength']].values])\n",
        "interactions_test, weights_test = data.build_interactions([tuple(i) for i in interactions_test_df[['personId', 'contentId', 'eventStrength']].values])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSALf77KWI1h",
        "outputId": "f7564d5a-bcfb-4c44-a63b-c51ee3f20b84"
      },
      "source": [
        "model = LightFM(loss='warp')\n",
        "model.fit(weights_train, item_features = tfidfs, epochs=30, num_threads=2)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightfm.lightfm.LightFM at 0x7fd8c0a73c90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGP3nKxwWIwW",
        "outputId": "0fee5900-9de3-46b0-f85f-5d9e0b939ff8"
      },
      "source": [
        "precision_at_k(model, weights_train, item_features=tfidfs, k=10).mean()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2195144"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEJlqNSjWIif",
        "outputId": "f3f93bd8-d31c-47d5-f56e-10b5ec8e71dd"
      },
      "source": [
        "precision_at_k(model, weights_test, item_features=tfidfs, k=10).mean()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.004378819"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiiRWS5RDaHm"
      },
      "source": [
        "Качество практически не изменилось, но я не занимался подбором гиперпараметров модели, поэтому его наверное можно было дальше улучшать\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SvUi_Fofgf5"
      },
      "source": [
        "# Ваш код здесь\n",
        "# feat = "
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Lwuex6PpsFw"
      },
      "source": [
        "## Задание 4. (2 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aZcHjSzp2cZ"
      },
      "source": [
        "В задании 3 мы использовали сырой текст статей. В этом задании необходимо сначала сделать предобработку текста (привести к нижнему регистру, убрать стоп слова, привести слова к номральной форме и т.д.), после чего обучите модель и оценить качество на тестовых данных."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUuZujW0zJKj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2a09004-f814-42bc-aed0-957d1e4fe557"
      },
      "source": [
        "import string\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "exclude = set(string.punctuation)\n",
        "exclude.update(stopwords.words('english'))\n",
        "exclude.update(stopwords.words('portuguese'))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCI7yNX0zGbn"
      },
      "source": [
        "def process_text(text):\n",
        "    return ' '.join([word for word in word_tokenize(text.lower()) if word not in exclude])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esBCmWYUzHUI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81315182-071b-4bac-fc86-f22f915a9b7c"
      },
      "source": [
        "articles_short['processed_text'] = articles_short['text'].astype('U').apply(process_text)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VV8YNfaVJayR"
      },
      "source": [
        "tfidf = TfidfVectorizer(min_df=25, max_features=50000).fit(list(articles_short['processed_text'].astype('U')))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWBSYPDvFW1d"
      },
      "source": [
        "tfidffs = tfidf.transform(list(articles_short['processed_text'].astype('U')))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLJ2-PqTzaxn"
      },
      "source": [
        "data = Dataset()\n",
        "\n",
        "data.fit(articles.personId.unique(),\n",
        "         articles.contentId.unique(),\n",
        "         item_features = pd.DataFrame(tfidffs)\n",
        "         )"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4r5lAoYJ1YX"
      },
      "source": [
        "interactions_train, weights_train = data.build_interactions([tuple(i) for i in interactions_train_df[['personId', 'contentId', 'eventStrength']].values])\n",
        "interactions_test, weights_test = data.build_interactions([tuple(i) for i in interactions_test_df[['personId', 'contentId', 'eventStrength']].values])\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PNYJW5LGaDQ",
        "outputId": "0f7a481e-a86c-4162-f368-233bef497fcc"
      },
      "source": [
        "model = LightFM(loss='warp')\n",
        "model.fit(weights_train, item_features = tfidffs, epochs=30, num_threads=2)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightfm.lightfm.LightFM at 0x7fd8bfeb8210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUWaaN2sGdGA",
        "outputId": "9569cc22-d12f-454c-9282-65ec367208d9"
      },
      "source": [
        "precision_at_k(model, weights_train, item_features=tfidffs, k=10).mean()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.23705037"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojGJ-VYMGc-C",
        "outputId": "90a2b24e-7db4-496e-8008-c0333b02578a"
      },
      "source": [
        "precision_at_k(model, weights_test, item_features=tfidffs, k=10).mean()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.004276986"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caKeomRFG6_i"
      },
      "source": [
        "Здесь я начал подозревать что либо оно переобучается, либо (что более вероятно) я что-то делаю не так"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDSaOLiJpdGj"
      },
      "source": [
        "# Ваш код здесь"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgayAPRpqn7L"
      },
      "source": [
        "Улучшилось ли качество предсказания?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKRzLLodq3gq"
      },
      "source": [
        "## Задание 5. (2 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brjHl49Aq8su"
      },
      "source": [
        "Подберите гиперпараметры модели LightFM (`n_components` и др.) для улучшения качества модели."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6bp3SP2HCa1",
        "outputId": "541c3e40-4172-47a1-b261-b55f3c317e52"
      },
      "source": [
        "model = LightFM(loss='warp', no_components=10, learning_rate=0.01, max_sampled=10)\n",
        "model.fit(weights_train, item_features = tfidffs, epochs=50, num_threads=2, verbose=True)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 50/50 [01:04<00:00,  1.29s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightfm.lightfm.LightFM at 0x7fd8c0a975d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbtaLs6vHCXc",
        "outputId": "a99952c4-c50c-4657-9011-b2ffdec967cd"
      },
      "source": [
        "precision_at_k(model, weights_train, item_features=tfidffs, k=10).mean()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.17715827"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHMyWMcAIy2k",
        "outputId": "907c491a-1ddd-4efa-d692-e4783480cbca"
      },
      "source": [
        "precision_at_k(model, weights_test, item_features=tfidffs, k=10).mean()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0045824847"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSMYT2MGNbm7"
      },
      "source": [
        "Ну технически оно немного выросло, в 1.071429 раз"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlwaeCiZqncD"
      },
      "source": [
        "# Ваш код здесь"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJA7v07NrYSF"
      },
      "source": [
        "## Бонусное задание. (3 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veLFUoVRrisk"
      },
      "source": [
        "Выше мы использовали достаточно простое представление текста статьи в виде TF-IDF. В этом задании Вам нужно представить текст статьи (можно вместе с заголовком) в виде эмбеддинга полученного с помощью рекуррентной сети или трансформера (можно использовать любую предобученную модель, которая Вам нравится). Обучите модель с ипользованием этих эмеддингов и сравните результаты с предыдущими."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMggKg3AKrBn"
      },
      "source": [
        "from gensim.models import FastText"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TH12D0LvHK8O"
      },
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3T2DV4UhHK5I"
      },
      "source": [
        "model = Word2Vec(list(articles_short['processed_text']), size=1500, min_count = 25)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWSRS9IKHK2O",
        "outputId": "61f89b10-8384-4726-967e-b670672c1b2e"
      },
      "source": [
        "def mean_vector(word2vec_model, string):\n",
        "    # remove out-of-vocabulary words\n",
        "    string = [word for word in string if word in word2vec_model.vocab]\n",
        "    if string:\n",
        "      return np.mean(word2vec_model[string], axis=0)\n",
        "    else:\n",
        "      return np.zeros(1000)\n",
        "\n",
        "trainx=[]\n",
        "i = 0\n",
        "for string in articles_short['processed_text']:\n",
        "    trainx.append(mean_vector(model.wv, string))\n",
        "    if i % 500 == 0:\n",
        "      print(i)\n",
        "    i+=1\n",
        "\n",
        "train_X = np.array(trainx)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "500\n",
            "1000\n",
            "1500\n",
            "2000\n",
            "2500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MetgUrORCbQ"
      },
      "source": [
        "data = Dataset()\n",
        "\n",
        "data.fit(articles.personId.unique(),\n",
        "         articles.contentId.unique(),\n",
        "         item_features = pd.DataFrame(train_X)\n",
        "         )\n",
        "\n",
        "interactions_train, weights_train = data.build_interactions([tuple(i) for i in interactions_train_df[['personId', 'contentId', 'eventStrength']].values])\n",
        "interactions_test, weights_test = data.build_interactions([tuple(i) for i in interactions_test_df[['personId', 'contentId', 'eventStrength']].values])\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdRo8ToTHKzS",
        "outputId": "f1e89d54-7935-43ca-e4b7-0132d5629eec"
      },
      "source": [
        "model = LightFM(loss='warp')\n",
        "model.fit(weights_train, item_features = sp.csr_matrix(train_X), epochs=30, num_threads=2, verbose=True)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 30/30 [03:43<00:00,  7.44s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightfm.lightfm.LightFM at 0x7fd8bd697490>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gieRuDHJQzrw",
        "outputId": "c92f25ae-ee92-4056-b94d-574ba658b8c3"
      },
      "source": [
        "precision_at_k(model, weights_train, item_features=sp.csr_matrix(train_X), k=10).mean()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.029766189"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5U6psw6Q0Hy",
        "outputId": "c8019545-9f82-40ae-f11f-6d639ec3ff04"
      },
      "source": [
        "precision_at_k(model, weights_test, item_features=sp.csr_matrix(train_X), k=10).mean()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0035641547"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiwfOZ3ySwye"
      },
      "source": [
        "Наверное я все-таки что-то делаю очень не так, ну либо рекомендательные системы игрушка дьявола ежжи"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQmn1cb-rXU3"
      },
      "source": [
        "# Ваш код здесь"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb_B5ZkMshtr"
      },
      "source": [
        ""
      ],
      "execution_count": 54,
      "outputs": []
    }
  ]
}